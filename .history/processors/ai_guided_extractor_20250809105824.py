"""
AI-Guided Diagram Extractor - S·ª≠ d·ª•ng AI ƒë·ªÉ nh·∫≠n di·ªán v·ªã tr√≠ h√¨nh v·∫Ω, OpenCV ƒë·ªÉ c·∫Øt ch√≠nh x√°c
"""
import os
import cv2
import numpy as np
from pathlib import Path
import base64
import json

class AIGuidedDiagramExtractor:
    """Class s·ª≠ d·ª•ng AI ƒë·ªÉ nh·∫≠n di·ªán h√¨nh v·∫Ω v√† OpenCV ƒë·ªÉ c·∫Øt ch√≠nh x√°c"""
    
    def __init__(self, output_dir="data/images"):
        self.output_dir = output_dir
        Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    def encode_image_to_base64(self, image_path):
        """Encode ·∫£nh th√†nh base64 ƒë·ªÉ g·ª≠i cho AI"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    def analyze_image_with_ai(self, image_path):
        """
        S·ª≠ d·ª•ng AI ƒë·ªÉ ph√¢n t√≠ch v√† t√¨m v·ªã tr√≠ h√¨nh v·∫Ω/b·∫£ng bi·ªÉu
        Tr·∫£ v·ªÅ danh s√°ch bounding boxes cho c√°c h√¨nh v·∫Ω
        """
        # Template prompt cho AI
        prompt = """
        H√£y ph√¢n t√≠ch ·∫£nh n√†y v√† t√¨m t·∫•t c·∫£ c√°c h√¨nh v·∫Ω, bi·ªÉu ƒë·ªì, b·∫£ng bi·ªÉu, h√¨nh h·ªçc trong ·∫£nh.
        
        Y√™u c·∫ßu:
        1. KH√îNG bao g·ªìm text thu·∫ßn t√∫y
        2. CH·ªà bao g·ªìm: h√¨nh h·ªçc, bi·ªÉu ƒë·ªì, b·∫£ng, s∆° ƒë·ªì, ƒë·ªì th·ªã
        3. Tr·∫£ v·ªÅ t·ªça ƒë·ªô bounding box d·∫°ng [x, y, width, height] (pixel)
        4. Th√™m m√¥ t·∫£ ng·∫Øn g·ªçn cho m·ªói h√¨nh v·∫Ω
        
        Format JSON:
        {
            "diagrams": [
                {
                    "bbox": [x, y, width, height],
                    "description": "m√¥ t·∫£ h√¨nh v·∫Ω",
                    "type": "geometry/chart/table/diagram"
                }
            ]
        }
        """
        
        # TODO: T√≠ch h·ª£p v·ªõi AI service (Vertex AI, OpenAI, etc.)
        # Hi·ªán t·∫°i return mock data ƒë·ªÉ demo
        return self._mock_ai_analysis(image_path)
    
    def _mock_ai_analysis(self, image_path):
        """Mock AI analysis ƒë·ªÉ demo - s·∫Ω thay b·∫±ng real AI call"""
        print(f"ü§ñ [MOCK] AI ƒëang ph√¢n t√≠ch {image_path}...")
        
        # ƒê·ªçc ·∫£nh ƒë·ªÉ l·∫•y k√≠ch th∆∞·ªõc
        img = cv2.imread(image_path)
        if img is None:
            return {"diagrams": []}
        
        h, w = img.shape[:2]
        
        # Mock data - gi·∫£ s·ª≠ AI t√¨m th·∫•y m·ªôt s·ªë h√¨nh v·∫Ω
        mock_results = {
            "diagrams": [
                {
                    "bbox": [int(w*0.1), int(h*0.2), int(w*0.3), int(h*0.2)],
                    "description": "H√¨nh h·ªçc tam gi√°c",
                    "type": "geometry"
                },
                {
                    "bbox": [int(w*0.6), int(h*0.4), int(w*0.25), int(h*0.3)],
                    "description": "Bi·ªÉu ƒë·ªì c·ªôt",
                    "type": "chart"
                }
            ]
        }
        
        print(f"ü§ñ AI t√¨m th·∫•y {len(mock_results['diagrams'])} h√¨nh v·∫Ω")
        return mock_results
    
    def extract_diagrams_with_ai(self, image_path, padding=10):
        """
        S·ª≠ d·ª•ng AI ƒë·ªÉ nh·∫≠n di·ªán v√† OpenCV ƒë·ªÉ c·∫Øt ch√≠nh x√°c
        
        Args:
            image_path: ƒë∆∞·ªùng d·∫´n ·∫£nh
            padding: ƒë·ªám khi c·∫Øt
            
        Returns:
            tuple (preview_path, diagram_paths, ai_results)
        """
        print(f"üîç B·∫Øt ƒë·∫ßu x·ª≠ l√Ω v·ªõi AI guidance: {image_path}")
        
        # B∆∞·ªõc 1: AI analysis
        ai_results = self.analyze_image_with_ai(image_path)
        
        if not ai_results.get("diagrams"):
            print("‚ö†Ô∏è AI kh√¥ng t√¨m th·∫•y h√¨nh v·∫Ω n√†o")
            return None, [], ai_results
        
        # B∆∞·ªõc 2: Load ·∫£nh
        original_image = cv2.imread(image_path)
        if original_image is None:
            raise FileNotFoundError(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
        
        h, w = original_image.shape[:2]
        
        # B∆∞·ªõc 3: T·∫°o preview v·ªõi AI bounding boxes
        preview_image = original_image.copy()
        diagram_paths = []
        base_name = Path(image_path).stem
        
        for i, diagram in enumerate(ai_results["diagrams"], 1):
            bbox = diagram["bbox"]
            x, y, width, height = bbox
            
            # Validate v√† adjust bbox
            x = max(0, min(x, w))
            y = max(0, min(y, h))
            width = min(width, w - x)
            height = min(height, h - y)
            
            if width <= 0 or height <= 0:
                print(f"‚ö†Ô∏è Bbox kh√¥ng h·ª£p l·ªá cho diagram {i}: {bbox}")
                continue
            
            # Th√™m padding
            x_start = max(0, x - padding)
            y_start = max(0, y - padding)
            x_end = min(w, x + width + padding)
            y_end = min(h, y + height + padding)
            
            # C·∫Øt diagram
            cropped = original_image[y_start:y_end, x_start:x_end]
            
            # L∆∞u diagram
            diagram_path = os.path.join(
                self.output_dir, 
                f"{base_name}_ai_diagram_{i:02d}.png"
            )
            cv2.imwrite(diagram_path, cropped)
            diagram_paths.append(diagram_path)
            
            # V·∫Ω bounding box tr√™n preview
            color = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)][i % 5]
            cv2.rectangle(preview_image, (x, y), (x + width, y + height), color, 2)
            
            # Th√™m label
            label = f"{i}. {diagram['type']}"
            cv2.putText(
                preview_image, label,
                (x, y - 10 if y > 20 else y + height + 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2
            )
            
            print(f"üíæ ƒê√£ l∆∞u AI diagram {i}: {diagram_path}")
            print(f"    üìù {diagram['description']} ({diagram['type']})")
        
        # L∆∞u preview
        preview_path = os.path.join(self.output_dir, f"{base_name}_ai_preview.png")
        cv2.imwrite(preview_path, preview_image)
        print(f"üíæ ƒê√£ l∆∞u AI preview: {preview_path}")
        
        return preview_path, diagram_paths, ai_results

class HybridDiagramExtractor:
    """Class k·∫øt h·ª£p c·∫£ OpenCV traditional v√† AI-guided approaches"""
    
    def __init__(self, output_dir="data/images"):
        self.output_dir = output_dir
        self.ai_extractor = AIGuidedDiagramExtractor(output_dir)
        # Import traditional extractor
        from diagram_extractor import DiagramExtractor
        self.cv_extractor = DiagramExtractor(output_dir)
    
    def extract_with_comparison(self, image_path):
        """
        So s√°nh k·∫øt qu·∫£ gi·ªØa traditional OpenCV v√† AI-guided
        
        Returns:
            dict ch·ª©a k·∫øt qu·∫£ t·ª´ c·∫£ hai ph∆∞∆°ng ph√°p
        """
        print(f"üîÑ So s√°nh Traditional CV vs AI-guided cho: {image_path}")
        print("="*60)
        
        results = {}
        
        # Ph∆∞∆°ng ph√°p 1: Traditional OpenCV (Strict mode)
        print("\nüîß TRADITIONAL OPENCV (STRICT MODE):")
        try:
            cv_preview, cv_diagrams, cv_stats = self.cv_extractor.extract_diagrams(
                image_path,
                min_size=100,
                max_area_ratio=0.2,
                aspect_range=(0.5, 2.0),
                solidity_range=(0.3, 0.8)
            )
            results['opencv'] = {
                'preview': cv_preview,
                'diagrams': cv_diagrams,
                'stats': cv_stats,
                'count': len(cv_diagrams)
            }
            print(f"‚úÖ OpenCV: {len(cv_diagrams)} diagrams")
        except Exception as e:
            print(f"‚ùå OpenCV error: {e}")
            results['opencv'] = {'error': str(e), 'count': 0}
        
        # Ph∆∞∆°ng ph√°p 2: AI-guided
        print("\nü§ñ AI-GUIDED APPROACH:")
        try:
            ai_preview, ai_diagrams, ai_results = self.ai_extractor.extract_diagrams_with_ai(image_path)
            results['ai_guided'] = {
                'preview': ai_preview,
                'diagrams': ai_diagrams,
                'ai_analysis': ai_results,
                'count': len(ai_diagrams) if ai_diagrams else 0
            }
            print(f"‚úÖ AI-guided: {len(ai_diagrams) if ai_diagrams else 0} diagrams")
        except Exception as e:
            print(f"‚ùå AI-guided error: {e}")
            results['ai_guided'] = {'error': str(e), 'count': 0}
        
        # So s√°nh k·∫øt qu·∫£
        print(f"\nüìä COMPARISON SUMMARY:")
        cv_count = results.get('opencv', {}).get('count', 0)
        ai_count = results.get('ai_guided', {}).get('count', 0)
        print(f"   Traditional OpenCV: {cv_count} diagrams")
        print(f"   AI-guided: {ai_count} diagrams")
        
        if cv_count > 0 and ai_count > 0:
            print(f"   üéØ AI-guided c√≥ th·ªÉ ch√≠nh x√°c h∆°n (semantic understanding)")
        elif cv_count > ai_count:
            print(f"   üìà OpenCV t√¨m ƒë∆∞·ª£c nhi·ªÅu h∆°n (c√≥ th·ªÉ bao g·ªìm false positives)")
        elif ai_count > cv_count:
            print(f"   ü§ñ AI t√¨m ƒë∆∞·ª£c nhi·ªÅu h∆°n (c√≥ th·ªÉ miss m·ªôt s·ªë trong OpenCV)")
        
        return results

# Mock integration v·ªõi Vertex AI (ƒë·ªÉ demo)
def integrate_with_vertex_ai():
    """
    Template ƒë·ªÉ t√≠ch h·ª£p v·ªõi Vertex AI th·ª±c t·∫ø
    """
    integration_code = '''
    # T√≠ch h·ª£p v·ªõi Vertex AI Gemini
    import vertexai
    from vertexai.generative_models import GenerativeModel, Part
    
    def analyze_image_with_vertex_ai(self, image_path):
        """S·ª≠ d·ª•ng Vertex AI Gemini ƒë·ªÉ ph√¢n t√≠ch ·∫£nh"""
        
        # Initialize Vertex AI
        vertexai.init(project="your-project-id", location="us-central1")
        
        # Load model
        model = GenerativeModel("gemini-2.0-flash-exp")
        
        # Prepare image
        image_part = Part.from_uri(image_path, mime_type="image/png")
        
        # Prompt
        prompt = """
        Analyze this image and identify all diagrams, charts, tables, and geometric figures.
        
        Requirements:
        1. DO NOT include plain text
        2. ONLY include: geometry, charts, tables, diagrams, graphs
        3. Return bounding box coordinates as [x, y, width, height] in pixels
        4. Add brief description for each figure
        
        Return JSON format:
        {
            "diagrams": [
                {
                    "bbox": [x, y, width, height],
                    "description": "description",
                    "type": "geometry/chart/table/diagram"
                }
            ]
        }
        """
        
        # Generate response
        response = model.generate_content([prompt, image_part])
        
        # Parse JSON response
        import json
        return json.loads(response.text)
    '''
    return integration_code

if __name__ == "__main__":
    print("üîß AI-Guided Diagram Extractor Demo")
    print("="*50)
    print("üìù ƒê√¢y l√† template ƒë·ªÉ t√≠ch h·ª£p AI v√†o vi·ªác c·∫Øt h√¨nh v·∫Ω")
    print("ü§ñ Hi·ªán t·∫°i s·ª≠ d·ª•ng mock data, c·∫ßn t√≠ch h·ª£p v·ªõi AI service th·ª±c t·∫ø")
    print("üí° Vertex AI integration code:")
    print(integrate_with_vertex_ai())
